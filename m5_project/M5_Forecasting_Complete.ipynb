{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0fd085",
   "metadata": {},
   "source": [
    "# M5 Forecasting - Previs√£o de Demanda Walmart\n",
    "\n",
    "## üéØ Objetivo\n",
    "Desenvolver um modelo preditivo de demanda para itens de varejo usando a base de dados Walmart M5 Forecasting.\n",
    "\n",
    "## üìã Estrutura do Projeto\n",
    "1. **Carregamento e An√°lise Explorat√≥ria**\n",
    "2. **Engenharia de Features**\n",
    "3. **Modelagem (LightGBM/XGBoost)**\n",
    "4. **Avalia√ß√£o e Visualiza√ß√µes**\n",
    "5. **Previs√µes Finais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes b√°sicas\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Adiciona o diret√≥rio src ao path\n",
    "project_root = r\"c:\\Users\\thiago.santos\\Desktop\\PESSOAL\\RandomF_XGB\\m5_project\"\n",
    "sys.path.append(os.path.join(project_root, 'src'))\n",
    "\n",
    "# Importa m√≥dulos do projeto\n",
    "from data_loader import M5DataLoader\n",
    "from feature_engineering import M5FeatureEngineer\n",
    "from modeling import M5Model, M5Ensemble\n",
    "from visualization import M5Visualizer\n",
    "from utils import MemoryManager, reduce_memory_usage, timer, check_environment\n",
    "import config\n",
    "\n",
    "print(\"‚úÖ M√≥dulos carregados com sucesso!\")\n",
    "print(\"\\nüìä Informa√ß√µes do ambiente:\")\n",
    "env_info = check_environment()\n",
    "for key, value in env_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae159b",
   "metadata": {},
   "source": [
    "## 1. üìÅ Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o carregador de dados\n",
    "with MemoryManager(verbose=True):\n",
    "    loader = M5DataLoader(config.DATA_PATH)\n",
    "    \n",
    "    # Carrega todos os dados\n",
    "    data_dict = loader.load_all_data()\n",
    "    \n",
    "    # Obt√©m informa√ß√µes b√°sicas\n",
    "    basic_info = loader.get_basic_info()\n",
    "    \n",
    "print(\"\\nüìà Informa√ß√µes B√°sicas dos Dados:\")\n",
    "for key, value in basic_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nüíæ Uso de Mem√≥ria:\")\n",
    "memory_info = loader.get_memory_usage()\n",
    "for key, value in memory_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f17a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessa o calendar\n",
    "calendar_processed = loader.preprocess_calendar()\n",
    "\n",
    "print(\"Calendar preprocessado!\")\n",
    "print(f\"Shape: {calendar_processed.shape}\")\n",
    "print(f\"Colunas adicionadas: {[col for col in calendar_processed.columns if col not in loader.calendar.columns]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de44ebb8",
   "metadata": {},
   "source": [
    "## 2. üîç An√°lise Explorat√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e58c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa visualizador\n",
    "viz = M5Visualizer()\n",
    "\n",
    "# Para an√°lise explorat√≥ria, vamos usar uma amostra dos dados\n",
    "# Converte dados para formato long (amostra)\n",
    "feature_eng = M5FeatureEngineer()\n",
    "\n",
    "# Usa apenas uma amostra para an√°lise explorat√≥ria\n",
    "sales_sample = data_dict['sales_train'].sample(n=1000, random_state=42)\n",
    "sample_melted = feature_eng.create_melted_data(sales_sample, calendar_processed)\n",
    "\n",
    "print(f\"Amostra para an√°lise: {len(sample_melted):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona pre√ßos √† amostra\n",
    "sample_with_prices = feature_eng.add_price_features(sample_melted, data_dict['sell_prices'])\n",
    "\n",
    "# Dashboard resumo\n",
    "viz.create_dashboard_summary(sample_with_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes explorat√≥rias\n",
    "print(\"üìä Gerando visualiza√ß√µes explorat√≥rias...\")\n",
    "\n",
    "# Overview das vendas\n",
    "viz.plot_sales_overview(sample_with_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd20f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padr√µes sazonais\n",
    "viz.plot_seasonal_patterns(sample_with_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ea239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de itens\n",
    "viz.plot_item_analysis(sample_with_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de pre√ßos\n",
    "viz.plot_price_analysis(sample_with_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef8c62",
   "metadata": {},
   "source": [
    "## 3. ‚öôÔ∏è Engenharia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o modelo completo, vamos usar mais dados\n",
    "# Seleciona uma amostra maior (ajuste conforme capacidade do sistema)\n",
    "sample_size = 5000  # Ajuste conforme sua mem√≥ria dispon√≠vel\n",
    "\n",
    "print(f\"üîß Iniciando engenharia de features com {sample_size} itens...\")\n",
    "\n",
    "with MemoryManager(verbose=True):\n",
    "    # Seleciona amostra dos dados\n",
    "    sales_modeling = data_dict['sales_train'].sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Aplica otimiza√ß√£o de mem√≥ria\n",
    "    if config.MEMORY_OPTIMIZATION:\n",
    "        sales_modeling = reduce_memory_usage(sales_modeling)\n",
    "        calendar_opt = reduce_memory_usage(calendar_processed.copy())\n",
    "        prices_opt = reduce_memory_usage(data_dict['sell_prices'].copy())\n",
    "    else:\n",
    "        calendar_opt = calendar_processed\n",
    "        prices_opt = data_dict['sell_prices']\n",
    "    \n",
    "    # Cria features completas\n",
    "    feature_data = feature_eng.create_all_features(\n",
    "        sales_modeling, \n",
    "        calendar_opt, \n",
    "        prices_opt\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Features criadas! Shape final: {feature_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de features para o modelo\n",
    "feature_cols = feature_eng.get_feature_list(feature_data)\n",
    "\n",
    "print(f\"üìù Total de features: {len(feature_cols)}\")\n",
    "print(f\"\\nPrimeiras 20 features:\")\n",
    "for i, feature in enumerate(feature_cols[:20]):\n",
    "    print(f\"  {i+1:2d}. {feature}\")\n",
    "    \n",
    "if len(feature_cols) > 20:\n",
    "    print(f\"  ... e mais {len(feature_cols) - 20} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd980c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove linhas com muitos NaN (principalmente dos lags iniciais)\n",
    "print(f\"üìä Dados antes da limpeza: {len(feature_data):,} registros\")\n",
    "\n",
    "# Remove linhas onde mais de 30% das features s√£o NaN\n",
    "threshold = len(feature_cols) * 0.7\n",
    "feature_data_clean = feature_data.dropna(subset=feature_cols, thresh=threshold)\n",
    "\n",
    "print(f\"üìä Dados ap√≥s limpeza: {len(feature_data_clean):,} registros\")\n",
    "print(f\"üìä Registros removidos: {len(feature_data) - len(feature_data_clean):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7b3d0",
   "metadata": {},
   "source": [
    "## 4. ü§ñ Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adfd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dados em treino e valida√ß√£o\n",
    "from utils import split_train_validation\n",
    "\n",
    "train_data, val_data = split_train_validation(feature_data_clean, validation_days=config.VALIDATION_DAYS)\n",
    "\n",
    "print(\"\\nüìä Distribui√ß√£o dos dados:\")\n",
    "print(f\"  Treino: {len(train_data):,} registros\")\n",
    "print(f\"  Valida√ß√£o: {len(val_data):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina modelo LightGBM\n",
    "print(\"üöÄ Treinando modelo LightGBM...\")\n",
    "\n",
    "with MemoryManager(verbose=True):\n",
    "    # Inicializa modelo\n",
    "    lgb_model = M5Model(model_type='lightgbm')\n",
    "    \n",
    "    # Prepara dados de treino\n",
    "    X_train, y_train = lgb_model.prepare_training_data(train_data, feature_cols)\n",
    "    \n",
    "    print(f\"Dados de treino preparados: {X_train.shape}\")\n",
    "    \n",
    "    # Treina com cross-validation\n",
    "    cv_results = lgb_model.time_series_split_train(X_train, y_train, n_splits=config.CV_SPLITS)\n",
    "    \n",
    "    print(\"\\n‚úÖ Treinamento conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza performance do modelo\n",
    "print(\"üìä Performance do modelo:\")\n",
    "\n",
    "# Resumo CV\n",
    "cv_summary = lgb_model.get_cv_summary()\n",
    "print(cv_summary)\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "viz.plot_model_performance(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "print(\"üéØ Import√¢ncia das Features:\")\n",
    "print(lgb_model.feature_importance.head(10))\n",
    "\n",
    "# Visualiza feature importance\n",
    "viz.plot_feature_importance(lgb_model.feature_importance, top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6455525f",
   "metadata": {},
   "source": [
    "## 5. üìà Avalia√ß√£o no Conjunto de Valida√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcc349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara dados de valida√ß√£o\n",
    "X_val, y_val = lgb_model.prepare_training_data(val_data, feature_cols)\n",
    "\n",
    "print(f\"Dados de valida√ß√£o: {X_val.shape}\")\n",
    "\n",
    "# Faz predi√ß√µes\n",
    "y_pred_val = lgb_model.predict(X_val)\n",
    "\n",
    "# Calcula m√©tricas\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "\n",
    "print(f\"\\nüìä M√©tricas de Valida√ß√£o:\")\n",
    "print(f\"  RMSE: {val_rmse:.4f}\")\n",
    "print(f\"  MAE: {val_mae:.4f}\")\n",
    "print(f\"  MAPE: {np.mean(np.abs((y_val - y_pred_val) / (y_val + 1e-8))) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a911d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza predi√ß√µes vs real\n",
    "viz.plot_predictions_vs_actual(y_val.values, y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d44f7",
   "metadata": {},
   "source": [
    "## 6. üéØ Compara√ß√£o com XGBoost (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina modelo XGBoost para compara√ß√£o\n",
    "print(\"üöÄ Treinando modelo XGBoost para compara√ß√£o...\")\n",
    "\n",
    "with MemoryManager(verbose=True):\n",
    "    # Inicializa modelo XGBoost\n",
    "    xgb_model = M5Model(model_type='xgboost')\n",
    "    \n",
    "    # Treina com uma amostra menor para compara√ß√£o r√°pida\n",
    "    sample_indices = np.random.choice(len(X_train), size=min(50000, len(X_train)), replace=False)\n",
    "    X_train_sample = X_train.iloc[sample_indices]\n",
    "    y_train_sample = y_train.iloc[sample_indices]\n",
    "    \n",
    "    cv_results_xgb = xgb_model.time_series_split_train(X_train_sample, y_train_sample, n_splits=2)\n",
    "    \n",
    "    print(\"\\n‚úÖ XGBoost treinado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8177ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compara modelos\n",
    "y_pred_val_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "val_rmse_xgb = np.sqrt(mean_squared_error(y_val, y_pred_val_xgb))\n",
    "val_mae_xgb = mean_absolute_error(y_val, y_pred_val_xgb)\n",
    "\n",
    "print(\"\\nüèÜ Compara√ß√£o de Modelos:\")\n",
    "print(f\"LightGBM:\")\n",
    "print(f\"  RMSE: {val_rmse:.4f}\")\n",
    "print(f\"  MAE: {val_mae:.4f}\")\n",
    "print(f\"\\nXGBoost:\")\n",
    "print(f\"  RMSE: {val_rmse_xgb:.4f}\")\n",
    "print(f\"  MAE: {val_mae_xgb:.4f}\")\n",
    "\n",
    "if val_rmse < val_rmse_xgb:\n",
    "    print(\"\\nü•á LightGBM tem melhor performance!\")\n",
    "    best_model = lgb_model\n",
    "else:\n",
    "    print(\"\\nü•á XGBoost tem melhor performance!\")\n",
    "    best_model = xgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f9f97",
   "metadata": {},
   "source": [
    "## 7. üíæ Salvamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o melhor modelo\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Cria diret√≥rio se n√£o existir\n",
    "os.makedirs(config.MODEL_PATH, exist_ok=True)\n",
    "\n",
    "# Nome do arquivo com timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f\"m5_model_{best_model.model_type}_{timestamp}.pkl\"\n",
    "model_filepath = os.path.join(config.MODEL_PATH, model_filename)\n",
    "\n",
    "# Salva modelo\n",
    "best_model.save_model(model_filepath)\n",
    "\n",
    "print(f\"‚úÖ Modelo salvo: {model_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106977f1",
   "metadata": {},
   "source": [
    "## 8. üìã Relat√≥rio Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relat√≥rio final detalhado\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ RELAT√ìRIO FINAL - M5 FORECASTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä DADOS UTILIZADOS:\")\n",
    "print(f\"  ‚Ä¢ Per√≠odo: {feature_data_clean['date'].min()} a {feature_data_clean['date'].max()}\")\n",
    "print(f\"  ‚Ä¢ Total de registros: {len(feature_data_clean):,}\")\n",
    "print(f\"  ‚Ä¢ Itens √∫nicos: {feature_data_clean['item_id'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Lojas: {feature_data_clean['store_id'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Features criadas: {len(feature_cols)}\")\n",
    "\n",
    "print(f\"\\nü§ñ MODELO SELECIONADO: {best_model.model_type.upper()}\")\n",
    "if best_model.cv_scores:\n",
    "    cv_rmse_mean = np.mean([r['val_rmse'] for r in best_model.cv_scores])\n",
    "    cv_rmse_std = np.std([r['val_rmse'] for r in best_model.cv_scores])\n",
    "    print(f\"  ‚Ä¢ RMSE CV: {cv_rmse_mean:.4f} ¬± {cv_rmse_std:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà PERFORMANCE NA VALIDA√á√ÉO:\")\n",
    "if best_model.model_type == 'lightgbm':\n",
    "    print(f\"  ‚Ä¢ RMSE: {val_rmse:.4f}\")\n",
    "    print(f\"  ‚Ä¢ MAE: {val_mae:.4f}\")\n",
    "else:\n",
    "    print(f\"  ‚Ä¢ RMSE: {val_rmse_xgb:.4f}\")\n",
    "    print(f\"  ‚Ä¢ MAE: {val_mae_xgb:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ TOP 5 FEATURES MAIS IMPORTANTES:\")\n",
    "for i, (_, row) in enumerate(best_model.feature_importance.head(5).iterrows()):\n",
    "    print(f\"  {i+1}. {row['feature']}: {row['importance']:.0f}\")\n",
    "\n",
    "print(f\"\\nüíæ ARQUIVOS GERADOS:\")\n",
    "print(f\"  ‚Ä¢ Modelo: {model_filepath}\")\n",
    "\n",
    "print(f\"\\nüèÜ CONCLUS√ïES:\")\n",
    "print(f\"  ‚Ä¢ Modelo treinado com sucesso\")\n",
    "print(f\"  ‚Ä¢ Features de lag e rolling mostraram-se importantes\")\n",
    "print(f\"  ‚Ä¢ Modelo pronto para previs√µes futuras\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1f60f",
   "metadata": {},
   "source": [
    "## 9. üîÆ Exemplo de Previs√£o Futura (Demonstra√ß√£o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstra√ß√£o de como fazer previs√µes futuras\n",
    "print(\"üîÆ Demonstra√ß√£o de previs√£o futura...\")\n",
    "\n",
    "# Para uma implementa√ß√£o completa, seria necess√°rio:\n",
    "# 1. Criar features para os pr√≥ximos 28 dias\n",
    "# 2. Usar rolling forecast (predizer 1 dia, atualizar features, predizer pr√≥ximo)\n",
    "# 3. Lidar com features de lag para dias futuros\n",
    "\n",
    "# Aqui vamos mostrar o processo com os √∫ltimos dados dispon√≠veis\n",
    "last_data = val_data.tail(1000)  # √öltimos dados como exemplo\n",
    "X_future, _ = best_model.prepare_training_data(last_data, feature_cols)\n",
    "\n",
    "# Faz predi√ß√£o\n",
    "future_predictions = best_model.predict(X_future)\n",
    "\n",
    "print(f\"\\nüìà Exemplo de previs√µes:\")\n",
    "print(f\"  ‚Ä¢ N√∫mero de previs√µes: {len(future_predictions)}\")\n",
    "print(f\"  ‚Ä¢ Demanda m√©dia prevista: {future_predictions.mean():.2f}\")\n",
    "print(f\"  ‚Ä¢ Demanda m√≠nima prevista: {future_predictions.min():.2f}\")\n",
    "print(f\"  ‚Ä¢ Demanda m√°xima prevista: {future_predictions.max():.2f}\")\n",
    "\n",
    "# Visualiza algumas previs√µes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(future_predictions[:100], label='Previs√µes', marker='o', markersize=3)\n",
    "plt.title('Exemplo de Previs√µes Futuras (Primeiros 100 pontos)')\n",
    "plt.xlabel('Pontos de Previs√£o')\n",
    "plt.ylabel('Demanda Prevista')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Demonstra√ß√£o conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459e552",
   "metadata": {},
   "source": [
    "## üìö Pr√≥ximos Passos\n",
    "\n",
    "Para uma implementa√ß√£o completa em produ√ß√£o, considere:\n",
    "\n",
    "1. **üîÑ Rolling Forecast**: Implementar previs√£o rolling para 28 dias futuros\n",
    "2. **üéõÔ∏è Hyperparameter Tuning**: Otimizar par√¢metros com Optuna ou GridSearch\n",
    "3. **üèóÔ∏è Ensemble Models**: Combinar m√∫ltiplos modelos para melhor performance\n",
    "4. **üìä WRMSSE Oficial**: Implementar a m√©trica oficial da competi√ß√£o\n",
    "5. **üöÄ MLOps**: Automatizar pipeline de retreinamento\n",
    "6. **üìà Monitoramento**: Tracking de performance em produ√ß√£o\n",
    "7. **üíæ Feature Store**: Centralizar features para reutiliza√ß√£o\n",
    "8. **üîç Interpretabilidade**: SHAP values para explicar predi√ß√µes\n",
    "\n",
    "---\n",
    "**‚ú® Projeto M5 Forecasting - Desenvolvido com abordagem modular e escal√°vel**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
