{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0fd085",
   "metadata": {},
   "source": [
    "# M5 Forecasting - Previsão de Demanda Walmart\n",
    "\n",
    "## 🎯 Objetivo\n",
    "Desenvolver um modelo preditivo de demanda para itens de varejo usando a base de dados Walmart M5 Forecasting.\n",
    "\n",
    "## 📋 Estrutura do Projeto\n",
    "1. **Carregamento e Análise Exploratória**\n",
    "2. **Engenharia de Features**\n",
    "3. **Modelagem (LightGBM/XGBoost)**\n",
    "4. **Avaliação e Visualizações**\n",
    "5. **Previsões Finais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações básicas\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Adiciona o diretório src ao path\n",
    "project_root = r\"c:\\Users\\thiago.santos\\Desktop\\PESSOAL\\RandomF_XGB\\m5_project\"\n",
    "sys.path.append(os.path.join(project_root, 'src'))\n",
    "\n",
    "# Importa módulos do projeto\n",
    "from data_loader import M5DataLoader\n",
    "from feature_engineering import M5FeatureEngineer\n",
    "from modeling import M5Model, M5Ensemble\n",
    "from visualization import M5Visualizer\n",
    "from utils import MemoryManager, reduce_memory_usage, timer, check_environment\n",
    "import config\n",
    "\n",
    "print(\"✅ Módulos carregados com sucesso!\")\n",
    "print(\"\\n📊 Informações do ambiente:\")\n",
    "env_info = check_environment()\n",
    "for key, value in env_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae159b",
   "metadata": {},
   "source": [
    "## 1. 📁 Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o carregador de dados\n",
    "with MemoryManager(verbose=True):\n",
    "    loader = M5DataLoader(config.DATA_PATH)\n",
    "    \n",
    "    # Carrega todos os dados\n",
    "    data_dict = loader.load_all_data()\n",
    "    \n",
    "    # Obtém informações básicas\n",
    "    basic_info = loader.get_basic_info()\n",
    "    \n",
    "print(\"\\n📈 Informações Básicas dos Dados:\")\n",
    "for key, value in basic_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n💾 Uso de Memória:\")\n",
    "memory_info = loader.get_memory_usage()\n",
    "for key, value in memory_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f17a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessa o calendar\n",
    "calendar_processed = loader.preprocess_calendar()\n",
    "\n",
    "print(\"Calendar preprocessado!\")\n",
    "print(f\"Shape: {calendar_processed.shape}\")\n",
    "print(f\"Colunas adicionadas: {[col for col in calendar_processed.columns if col not in loader.calendar.columns]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de44ebb8",
   "metadata": {},
   "source": [
    "## 2. 🔍 Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e58c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa visualizador\n",
    "viz = M5Visualizer()\n",
    "\n",
    "# Para análise exploratória, vamos usar uma amostra dos dados\n",
    "# Converte dados para formato long (amostra)\n",
    "feature_eng = M5FeatureEngineer()\n",
    "\n",
    "# Usa apenas uma amostra para análise exploratória\n",
    "sales_sample = data_dict['sales_train'].sample(n=1000, random_state=42)\n",
    "sample_melted = feature_eng.create_melted_data(sales_sample, calendar_processed)\n",
    "\n",
    "print(f\"Amostra para análise: {len(sample_melted):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona preços à amostra\n",
    "sample_with_prices = feature_eng.add_price_features(sample_melted, data_dict['sell_prices'])\n",
    "\n",
    "# Dashboard resumo\n",
    "viz.create_dashboard_summary(sample_with_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizações exploratórias\n",
    "print(\"📊 Gerando visualizações exploratórias...\")\n",
    "\n",
    "# Overview das vendas\n",
    "viz.plot_sales_overview(sample_with_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd20f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padrões sazonais\n",
    "viz.plot_seasonal_patterns(sample_with_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ea239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de itens\n",
    "viz.plot_item_analysis(sample_with_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de preços\n",
    "viz.plot_price_analysis(sample_with_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef8c62",
   "metadata": {},
   "source": [
    "## 3. ⚙️ Engenharia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o modelo completo, vamos usar mais dados\n",
    "# Seleciona uma amostra maior (ajuste conforme capacidade do sistema)\n",
    "sample_size = 5000  # Ajuste conforme sua memória disponível\n",
    "\n",
    "print(f\"🔧 Iniciando engenharia de features com {sample_size} itens...\")\n",
    "\n",
    "with MemoryManager(verbose=True):\n",
    "    # Seleciona amostra dos dados\n",
    "    sales_modeling = data_dict['sales_train'].sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Aplica otimização de memória\n",
    "    if config.MEMORY_OPTIMIZATION:\n",
    "        sales_modeling = reduce_memory_usage(sales_modeling)\n",
    "        calendar_opt = reduce_memory_usage(calendar_processed.copy())\n",
    "        prices_opt = reduce_memory_usage(data_dict['sell_prices'].copy())\n",
    "    else:\n",
    "        calendar_opt = calendar_processed\n",
    "        prices_opt = data_dict['sell_prices']\n",
    "    \n",
    "    # Cria features completas\n",
    "    feature_data = feature_eng.create_all_features(\n",
    "        sales_modeling, \n",
    "        calendar_opt, \n",
    "        prices_opt\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✅ Features criadas! Shape final: {feature_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de features para o modelo\n",
    "feature_cols = feature_eng.get_feature_list(feature_data)\n",
    "\n",
    "print(f\"📝 Total de features: {len(feature_cols)}\")\n",
    "print(f\"\\nPrimeiras 20 features:\")\n",
    "for i, feature in enumerate(feature_cols[:20]):\n",
    "    print(f\"  {i+1:2d}. {feature}\")\n",
    "    \n",
    "if len(feature_cols) > 20:\n",
    "    print(f\"  ... e mais {len(feature_cols) - 20} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd980c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove linhas com muitos NaN (principalmente dos lags iniciais)\n",
    "print(f\"📊 Dados antes da limpeza: {len(feature_data):,} registros\")\n",
    "\n",
    "# Remove linhas onde mais de 30% das features são NaN\n",
    "threshold = len(feature_cols) * 0.7\n",
    "feature_data_clean = feature_data.dropna(subset=feature_cols, thresh=threshold)\n",
    "\n",
    "print(f\"📊 Dados após limpeza: {len(feature_data_clean):,} registros\")\n",
    "print(f\"📊 Registros removidos: {len(feature_data) - len(feature_data_clean):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7b3d0",
   "metadata": {},
   "source": [
    "## 4. 🤖 Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adfd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dados em treino e validação\n",
    "from utils import split_train_validation\n",
    "\n",
    "train_data, val_data = split_train_validation(feature_data_clean, validation_days=config.VALIDATION_DAYS)\n",
    "\n",
    "print(\"\\n📊 Distribuição dos dados:\")\n",
    "print(f\"  Treino: {len(train_data):,} registros\")\n",
    "print(f\"  Validação: {len(val_data):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina modelo LightGBM\n",
    "print(\"🚀 Treinando modelo LightGBM...\")\n",
    "\n",
    "with MemoryManager(verbose=True):\n",
    "    # Inicializa modelo\n",
    "    lgb_model = M5Model(model_type='lightgbm')\n",
    "    \n",
    "    # Prepara dados de treino\n",
    "    X_train, y_train = lgb_model.prepare_training_data(train_data, feature_cols)\n",
    "    \n",
    "    print(f\"Dados de treino preparados: {X_train.shape}\")\n",
    "    \n",
    "    # Treina com cross-validation\n",
    "    cv_results = lgb_model.time_series_split_train(X_train, y_train, n_splits=config.CV_SPLITS)\n",
    "    \n",
    "    print(\"\\n✅ Treinamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza performance do modelo\n",
    "print(\"📊 Performance do modelo:\")\n",
    "\n",
    "# Resumo CV\n",
    "cv_summary = lgb_model.get_cv_summary()\n",
    "print(cv_summary)\n",
    "\n",
    "# Visualização\n",
    "viz.plot_model_performance(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "print(\"🎯 Importância das Features:\")\n",
    "print(lgb_model.feature_importance.head(10))\n",
    "\n",
    "# Visualiza feature importance\n",
    "viz.plot_feature_importance(lgb_model.feature_importance, top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6455525f",
   "metadata": {},
   "source": [
    "## 5. 📈 Avaliação no Conjunto de Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcc349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara dados de validação\n",
    "X_val, y_val = lgb_model.prepare_training_data(val_data, feature_cols)\n",
    "\n",
    "print(f\"Dados de validação: {X_val.shape}\")\n",
    "\n",
    "# Faz predições\n",
    "y_pred_val = lgb_model.predict(X_val)\n",
    "\n",
    "# Calcula métricas\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "\n",
    "print(f\"\\n📊 Métricas de Validação:\")\n",
    "print(f\"  RMSE: {val_rmse:.4f}\")\n",
    "print(f\"  MAE: {val_mae:.4f}\")\n",
    "print(f\"  MAPE: {np.mean(np.abs((y_val - y_pred_val) / (y_val + 1e-8))) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a911d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza predições vs real\n",
    "viz.plot_predictions_vs_actual(y_val.values, y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d44f7",
   "metadata": {},
   "source": [
    "## 6. 🎯 Comparação com XGBoost (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina modelo XGBoost para comparação\n",
    "print(\"🚀 Treinando modelo XGBoost para comparação...\")\n",
    "\n",
    "with MemoryManager(verbose=True):\n",
    "    # Inicializa modelo XGBoost\n",
    "    xgb_model = M5Model(model_type='xgboost')\n",
    "    \n",
    "    # Treina com uma amostra menor para comparação rápida\n",
    "    sample_indices = np.random.choice(len(X_train), size=min(50000, len(X_train)), replace=False)\n",
    "    X_train_sample = X_train.iloc[sample_indices]\n",
    "    y_train_sample = y_train.iloc[sample_indices]\n",
    "    \n",
    "    cv_results_xgb = xgb_model.time_series_split_train(X_train_sample, y_train_sample, n_splits=2)\n",
    "    \n",
    "    print(\"\\n✅ XGBoost treinado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8177ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compara modelos\n",
    "y_pred_val_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "val_rmse_xgb = np.sqrt(mean_squared_error(y_val, y_pred_val_xgb))\n",
    "val_mae_xgb = mean_absolute_error(y_val, y_pred_val_xgb)\n",
    "\n",
    "print(\"\\n🏆 Comparação de Modelos:\")\n",
    "print(f\"LightGBM:\")\n",
    "print(f\"  RMSE: {val_rmse:.4f}\")\n",
    "print(f\"  MAE: {val_mae:.4f}\")\n",
    "print(f\"\\nXGBoost:\")\n",
    "print(f\"  RMSE: {val_rmse_xgb:.4f}\")\n",
    "print(f\"  MAE: {val_mae_xgb:.4f}\")\n",
    "\n",
    "if val_rmse < val_rmse_xgb:\n",
    "    print(\"\\n🥇 LightGBM tem melhor performance!\")\n",
    "    best_model = lgb_model\n",
    "else:\n",
    "    print(\"\\n🥇 XGBoost tem melhor performance!\")\n",
    "    best_model = xgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f9f97",
   "metadata": {},
   "source": [
    "## 7. 💾 Salvamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o melhor modelo\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Cria diretório se não existir\n",
    "os.makedirs(config.MODEL_PATH, exist_ok=True)\n",
    "\n",
    "# Nome do arquivo com timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f\"m5_model_{best_model.model_type}_{timestamp}.pkl\"\n",
    "model_filepath = os.path.join(config.MODEL_PATH, model_filename)\n",
    "\n",
    "# Salva modelo\n",
    "best_model.save_model(model_filepath)\n",
    "\n",
    "print(f\"✅ Modelo salvo: {model_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106977f1",
   "metadata": {},
   "source": [
    "## 8. 📋 Relatório Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatório final detalhado\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 RELATÓRIO FINAL - M5 FORECASTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n📊 DADOS UTILIZADOS:\")\n",
    "print(f\"  • Período: {feature_data_clean['date'].min()} a {feature_data_clean['date'].max()}\")\n",
    "print(f\"  • Total de registros: {len(feature_data_clean):,}\")\n",
    "print(f\"  • Itens únicos: {feature_data_clean['item_id'].nunique():,}\")\n",
    "print(f\"  • Lojas: {feature_data_clean['store_id'].nunique()}\")\n",
    "print(f\"  • Features criadas: {len(feature_cols)}\")\n",
    "\n",
    "print(f\"\\n🤖 MODELO SELECIONADO: {best_model.model_type.upper()}\")\n",
    "if best_model.cv_scores:\n",
    "    cv_rmse_mean = np.mean([r['val_rmse'] for r in best_model.cv_scores])\n",
    "    cv_rmse_std = np.std([r['val_rmse'] for r in best_model.cv_scores])\n",
    "    print(f\"  • RMSE CV: {cv_rmse_mean:.4f} ± {cv_rmse_std:.4f}\")\n",
    "\n",
    "print(f\"\\n📈 PERFORMANCE NA VALIDAÇÃO:\")\n",
    "if best_model.model_type == 'lightgbm':\n",
    "    print(f\"  • RMSE: {val_rmse:.4f}\")\n",
    "    print(f\"  • MAE: {val_mae:.4f}\")\n",
    "else:\n",
    "    print(f\"  • RMSE: {val_rmse_xgb:.4f}\")\n",
    "    print(f\"  • MAE: {val_mae_xgb:.4f}\")\n",
    "\n",
    "print(f\"\\n🎯 TOP 5 FEATURES MAIS IMPORTANTES:\")\n",
    "for i, (_, row) in enumerate(best_model.feature_importance.head(5).iterrows()):\n",
    "    print(f\"  {i+1}. {row['feature']}: {row['importance']:.0f}\")\n",
    "\n",
    "print(f\"\\n💾 ARQUIVOS GERADOS:\")\n",
    "print(f\"  • Modelo: {model_filepath}\")\n",
    "\n",
    "print(f\"\\n🏆 CONCLUSÕES:\")\n",
    "print(f\"  • Modelo treinado com sucesso\")\n",
    "print(f\"  • Features de lag e rolling mostraram-se importantes\")\n",
    "print(f\"  • Modelo pronto para previsões futuras\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1f60f",
   "metadata": {},
   "source": [
    "## 9. 🔮 Exemplo de Previsão Futura (Demonstração)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração de como fazer previsões futuras\n",
    "print(\"🔮 Demonstração de previsão futura...\")\n",
    "\n",
    "# Para uma implementação completa, seria necessário:\n",
    "# 1. Criar features para os próximos 28 dias\n",
    "# 2. Usar rolling forecast (predizer 1 dia, atualizar features, predizer próximo)\n",
    "# 3. Lidar com features de lag para dias futuros\n",
    "\n",
    "# Aqui vamos mostrar o processo com os últimos dados disponíveis\n",
    "last_data = val_data.tail(1000)  # Últimos dados como exemplo\n",
    "X_future, _ = best_model.prepare_training_data(last_data, feature_cols)\n",
    "\n",
    "# Faz predição\n",
    "future_predictions = best_model.predict(X_future)\n",
    "\n",
    "print(f\"\\n📈 Exemplo de previsões:\")\n",
    "print(f\"  • Número de previsões: {len(future_predictions)}\")\n",
    "print(f\"  • Demanda média prevista: {future_predictions.mean():.2f}\")\n",
    "print(f\"  • Demanda mínima prevista: {future_predictions.min():.2f}\")\n",
    "print(f\"  • Demanda máxima prevista: {future_predictions.max():.2f}\")\n",
    "\n",
    "# Visualiza algumas previsões\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(future_predictions[:100], label='Previsões', marker='o', markersize=3)\n",
    "plt.title('Exemplo de Previsões Futuras (Primeiros 100 pontos)')\n",
    "plt.xlabel('Pontos de Previsão')\n",
    "plt.ylabel('Demanda Prevista')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Demonstração concluída!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459e552",
   "metadata": {},
   "source": [
    "## 📚 Próximos Passos\n",
    "\n",
    "Para uma implementação completa em produção, considere:\n",
    "\n",
    "1. **🔄 Rolling Forecast**: Implementar previsão rolling para 28 dias futuros\n",
    "2. **🎛️ Hyperparameter Tuning**: Otimizar parâmetros com Optuna ou GridSearch\n",
    "3. **🏗️ Ensemble Models**: Combinar múltiplos modelos para melhor performance\n",
    "4. **📊 WRMSSE Oficial**: Implementar a métrica oficial da competição\n",
    "5. **🚀 MLOps**: Automatizar pipeline de retreinamento\n",
    "6. **📈 Monitoramento**: Tracking de performance em produção\n",
    "7. **💾 Feature Store**: Centralizar features para reutilização\n",
    "8. **🔍 Interpretabilidade**: SHAP values para explicar predições\n",
    "\n",
    "---\n",
    "**✨ Projeto M5 Forecasting - Desenvolvido com abordagem modular e escalável**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
